{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preverjanje urne popolnosti meritev\n",
    "\n",
    "Notebook preveri, ali ima vsako merilno mesto zapis za vsako uro v svojem 훾asovnem razponu, ali so vsi 탑igi na polno uro ter ali imajo vse postaje enak 훾asovni za훾etek/konec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c855dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e4d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/original\")\n",
    "files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "len(files), files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44bc119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hourly_completeness(csv_path: Path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"datetime\" not in df.columns:\n",
    "        raise ValueError(f\"Datoteka {csv_path.name} nima stolpca 'datetime'.\")\n",
    "\n",
    "    dt = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    invalid_count = int(dt.isna().sum())\n",
    "\n",
    "    valid_dt = dt.dropna().sort_values()\n",
    "    if valid_dt.empty:\n",
    "        return {\n",
    "            \"station\": csv_path.stem,\n",
    "            \"rows\": len(df),\n",
    "            \"first\": pd.NaT,\n",
    "            \"last\": pd.NaT,\n",
    "            \"expected_hours\": 0,\n",
    "            \"actual_unique_hours\": 0,\n",
    "            \"missing_hours\": 0,\n",
    "            \"duplicate_hours\": 0,\n",
    "            \"invalid_datetime\": invalid_count,\n",
    "            \"off_hour_timestamps\": 0,\n",
    "            \"missing_list\": []\n",
    "        }\n",
    "\n",
    "    off_hour_count = int(((valid_dt.dt.minute != 0) | (valid_dt.dt.second != 0) | (valid_dt.dt.microsecond != 0)).sum())\n",
    "\n",
    "    unique_hours = valid_dt.drop_duplicates()\n",
    "    unique_hours_index = pd.DatetimeIndex(unique_hours.to_numpy())\n",
    "    full_index = pd.date_range(unique_hours_index.min(), unique_hours_index.max(), freq=\"h\")\n",
    "    missing = full_index.difference(unique_hours_index)\n",
    "\n",
    "    return {\n",
    "        \"station\": csv_path.stem,\n",
    "        \"rows\": len(df),\n",
    "        \"first\": unique_hours.min(),\n",
    "        \"last\": unique_hours.max(),\n",
    "        \"expected_hours\": len(full_index),\n",
    "        \"actual_unique_hours\": len(unique_hours),\n",
    "        \"missing_hours\": len(missing),\n",
    "        \"duplicate_hours\": int(valid_dt.size - unique_hours.size),\n",
    "        \"invalid_datetime\": invalid_count,\n",
    "        \"off_hour_timestamps\": off_hour_count,\n",
    "        \"missing_list\": missing.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae96fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>rows</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>expected_hours</th>\n",
       "      <th>actual_unique_hours</th>\n",
       "      <th>missing_hours</th>\n",
       "      <th>duplicate_hours</th>\n",
       "      <th>invalid_datetime</th>\n",
       "      <th>off_hour_timestamps</th>\n",
       "      <th>same_global_start</th>\n",
       "      <th>same_global_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station, rows, first, last, expected_hours, actual_unique_hours, missing_hours, duplicate_hours, invalid_datetime, off_hour_timestamps, same_global_start, same_global_end]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "errors = []\n",
    "\n",
    "for path in files:\n",
    "    try:\n",
    "        row = check_hourly_completeness(path)\n",
    "        if isinstance(row, dict):\n",
    "            results.append(row)\n",
    "        else:\n",
    "            errors.append({\"file\": path.name, \"error\": \"Result is not a dict\"})\n",
    "    except Exception as e:\n",
    "        errors.append({\"file\": path.name, \"error\": str(e)})\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "if not summary.empty and \"station\" in summary.columns:\n",
    "    summary = summary.sort_values(\"station\").reset_index(drop=True)\n",
    "\n",
    "if errors:\n",
    "    print(f\"Napake pri preverjanju: {len(errors)}\")\n",
    "    print(pd.DataFrame(errors).head(20))\n",
    "\n",
    "if not summary.empty and {\"first\", \"last\"}.issubset(summary.columns):\n",
    "    global_first = summary[\"first\"].min()\n",
    "    global_last = summary[\"last\"].max()\n",
    "    summary[\"same_global_start\"] = summary[\"first\"] == global_first\n",
    "    summary[\"same_global_end\"] = summary[\"last\"] == global_last\n",
    "else:\n",
    "    summary[\"same_global_start\"] = pd.Series(dtype=bool)\n",
    "    summary[\"same_global_end\"] = pd.Series(dtype=bool)\n",
    "\n",
    "cols = [\n",
    "    \"station\", \"rows\", \"first\", \"last\",\n",
    "    \"expected_hours\", \"actual_unique_hours\",\n",
    "    \"missing_hours\", \"duplicate_hours\",\n",
    "    \"invalid_datetime\", \"off_hour_timestamps\",\n",
    "    \"same_global_start\", \"same_global_end\"\n",
    "]\n",
    "for c in cols:\n",
    "    if c not in summary.columns:\n",
    "        summary[c] = pd.Series(dtype=\"object\")\n",
    "\n",
    "summary[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8addde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>missing_hours</th>\n",
       "      <th>duplicate_hours</th>\n",
       "      <th>invalid_datetime</th>\n",
       "      <th>off_hour_timestamps</th>\n",
       "      <th>same_global_start</th>\n",
       "      <th>same_global_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station, missing_hours, duplicate_hours, invalid_datetime, off_hour_timestamps, same_global_start, same_global_end]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues = summary[(summary[\"missing_hours\"] > 0) | (summary[\"duplicate_hours\"] > 0) | (summary[\"invalid_datetime\"] > 0) | (summary[\"off_hour_timestamps\"] > 0) | (~summary[\"same_global_start\"]) | (~summary[\"same_global_end\"])]\n",
    "issues[[\"station\", \"missing_hours\", \"duplicate_hours\", \"invalid_datetime\", \"off_hour_timestamps\", \"same_global_start\", \"same_global_end\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c9ee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>missing_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station, missing_datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_hours_table(summary_df: pd.DataFrame):\n",
    "    rows = []\n",
    "    for _, row in summary_df.iterrows():\n",
    "        station = row[\"station\"]\n",
    "        for ts in row[\"missing_list\"]:\n",
    "            rows.append({\"station\": station, \"missing_datetime\": ts})\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"station\", \"missing_datetime\"])\n",
    "    return pd.DataFrame(rows).sort_values([\"station\", \"missing_datetime\"]).reset_index(drop=True)\n",
    "\n",
    "missing_detail = missing_hours_table(summary)\n",
    "missing_detail.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa04d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Globalni skupni razpon:\n",
      "- zacetek: 2024-05-02 20:00:00\n",
      "- konec:   2025-12-11 07:00:00\n",
      "\n",
      "Skupni pregled kontrol:\n",
      "- postaje z manjkajocimi urami: 0\n",
      "- postaje s podvojenimi urami:   0\n",
      "- postaje z neveljavnim casom:  0\n",
      "- postaje izven polne ure:      0\n",
      "- postaje z drugim zacetkom:    0\n",
      "- postaje z drugim koncem:      0\n"
     ]
    }
   ],
   "source": [
    "print(\"Globalni skupni razpon:\")\n",
    "print(f\"- zacetek: {global_first}\")\n",
    "print(f\"- konec:   {global_last}\")\n",
    "print()\n",
    "print(\"Skupni pregled kontrol:\")\n",
    "print(f\"- postaje z manjkajocimi urami: {(summary['missing_hours'] > 0).sum()}\")\n",
    "print(f\"- postaje s podvojenimi urami:   {(summary['duplicate_hours'] > 0).sum()}\")\n",
    "print(f\"- postaje z neveljavnim casom:  {(summary['invalid_datetime'] > 0).sum()}\")\n",
    "print(f\"- postaje izven polne ure:      {(summary['off_hour_timestamps'] > 0).sum()}\")\n",
    "print(f\"- postaje z drugim zacetkom:    {(~summary['same_global_start']).sum()}\")\n",
    "print(f\"- postaje z drugim koncem:      {(~summary['same_global_end']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4535c760",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['missing_list'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m OUTPUT_DIR = Path(\u001b[33m\"\u001b[39m\u001b[33m../reports\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m OUTPUT_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmissing_list\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.to_csv(OUTPUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mhourly_completeness_summary.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m missing_detail.to_csv(OUTPUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mhourly_missing_hours_detail.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShranjeno:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-pytorch/lib/python3.11/site-packages/pandas/core/frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-pytorch/lib/python3.11/site-packages/pandas/core/generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-pytorch/lib/python3.11/site-packages/pandas/core/generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-pytorch/lib/python3.11/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['missing_list'] not found in axis\""
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(\"../reports\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary.drop(columns=[\"missing_list\"]).to_csv(OUTPUT_DIR / \"hourly_completeness_summary.csv\", index=False)\n",
    "missing_detail.to_csv(OUTPUT_DIR / \"hourly_missing_hours_detail.csv\", index=False)\n",
    "\n",
    "print(\"Shranjeno:\")\n",
    "print(OUTPUT_DIR / \"hourly_completeness_summary.csv\")\n",
    "print(OUTPUT_DIR / \"hourly_missing_hours_detail.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
